<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=180&section=header&text=Sense%20AI&fontSize=42&fontColor=fff&animation=twinkling&fontAlignY=32&desc=Multimodal%20Emotion%20%26%20Sentiment%20Intelligence%20Platform&descAlignY=55&descSize=16" width="100%"/>

<br/>

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![Django](https://img.shields.io/badge/Django-5.2-092E20?style=for-the-badge&logo=django&logoColor=white)](https://djangoproject.com)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://tensorflow.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.6-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![HuggingFace](https://img.shields.io/badge/ðŸ¤—_Transformers-4.36-FFD21E?style=for-the-badge)](https://huggingface.co)
[![OpenAI Whisper](https://img.shields.io/badge/Whisper-ASR-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com/research/whisper)

<br/>

> **Sense AI** is a production-grade multimodal AI platform that understands human emotion and sentiment across images, video, audio, and text â€” all through a unified REST API.

<br/>

</div>

---

## What It Does

Sense AI brings together six specialized AI pipelines under one platform. Feed it an image, a video, an audio clip, or raw text â€” and it returns deep emotional and semantic intelligence in real time.

| Pipeline | Input | Output |
|---|---|---|
| ðŸ–¼ï¸ Image Emotion | Face image | Emotion label + confidence |
| ðŸŽ¬ Video Analysis | Video file | Full emotion timeline + audio transcription + PDF report |
| ðŸ“¹ Real-Time Video | Live stream frames | Per-frame emotion with session tracking |
| ðŸŽ™ï¸ Speech to Text | Audio file | Transcription + summary + sentiment |
| ðŸ’¬ Sentiment Analysis | Text | Positive / Negative classification |
| ðŸ“ Text Summarizer | Long text | Abstractive summary via BART |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Sense AI Platform                     â”‚
â”‚                     Django REST Framework                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Image  â”‚      â”‚   Video   â”‚    â”‚  Real-Time  â”‚
    â”‚Emotion  â”‚      â”‚ Analysis  â”‚    â”‚   Video     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚         Custom CNN â€” emotion_model.h5          â”‚
    â”‚    7-class: AngryÂ·DisgustÂ·FearÂ·HappyÂ·          â”‚
    â”‚            NeutralÂ·SadÂ·Surprise                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Speech2Text â”‚    â”‚  Sentiment   â”‚    â”‚  Text Summarizer   â”‚
    â”‚              â”‚    â”‚  Analysis    â”‚    â”‚                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚OpenAI Whisperâ”‚   â”‚ TF-IDF +     â”‚    â”‚ facebook/bart-      â”‚
    â”‚  (base ASR) â”‚    â”‚sklearn Model â”‚    â”‚ large-cnn (BART)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## AI Models

### ðŸ§  Custom Emotion CNN
A convolutional neural network trained on facial expression datasets, designed for real-time inference.

- **Architecture:** CNN with multiple Conv2D â†’ MaxPooling â†’ Dropout blocks, fully connected output
- **Input:** 48Ã—48 grayscale face crops
- **Output:** 7 emotion classes with softmax probability distribution
- **Classes:** `Angry` Â· `Disgust` Â· `Fear` Â· `Happy` Â· `Neutral` Â· `Sad` Â· `Surprise`
- **Format:** Keras `.h5` â€” optimized for fast batch inference
- **Deployed:** Shared across Image and Video pipelines (loaded once at server startup)

### ðŸŽ™ï¸ OpenAI Whisper
- **Model:** `whisper-base` â€” 74M parameters
- **Task:** Multilingual speech recognition, fine-tuned on 680K hours of audio
- **Usage:** Audio extraction from video + standalone audio files
- **Language:** English with fallback prompt engineering

### ðŸ“Š TF-IDF Sentiment Classifier
- **Pipeline:** TF-IDF vectorizer â†’ trained scikit-learn classifier
- **Task:** Binary sentiment classification (Positive / Negative)
- **Threshold:** `prediction â‰¥ 0.5` â†’ Positive
- **Shared:** Reused across Sentiment Analysis, Speech2Text, and Video Analysis pipelines

### ðŸ“ BART Large CNN (HuggingFace)
- **Model:** `facebook/bart-large-cnn` â€” 400M parameters
- **Task:** Abstractive text summarization
- **Framework:** HuggingFace Transformers pipeline
- **Inference:** `do_sample=False` for deterministic output

---

## API Endpoints

```
POST   /api/emotion-image/           â†’  Analyze emotion from image
POST   /api/emotion-video/           â†’  Full video analysis + PDF report
POST   /api/realtime-video/          â†’  Real-time frame emotion detection
POST   /api/speech2text/             â†’  Transcribe + sentiment from audio
POST   /api/sentiment/               â†’  Text sentiment classification
POST   /api/summarizer/              â†’  Abstractive text summarization

GET    /api/emotion-image/{id}/      â†’  Retrieve past image analysis
GET    /api/emotion-video/{id}/      â†’  Retrieve video analysis + download PDF
GET    /api/realtime-video/{id}/     â†’  Retrieve session frames + results
GET    /api/speech2text/{id}/        â†’  Retrieve transcription result
GET    /api/sentiment/{id}/          â†’  Retrieve sentiment result
GET    /api/summarizer/{id}/         â†’  Retrieve summary result
```

### Example â€” Emotion from Image

```bash
curl -X POST https://your-domain/api/emotion-image/ \
  -F "image=@face.jpg"
```

```json
{
  "id": 1,
  "emotion": "Happy",
  "confidence": 0.9731,
  "created_at": "2025-02-22T14:30:00Z"
}
```

### Example â€” Video Full Analysis

```bash
curl -X POST https://your-domain/api/emotion-video/ \
  -F "video=@session.mp4"
```

```json
{
  "id": 5,
  "dominant_emotion": "Neutral",
  "emotion_percentages": {
    "Happy": 34.2,
    "Neutral": 41.5,
    "Sad": 12.1,
    "Angry": 8.0,
    "Fear": 4.2
  },
  "transcription": "...",
  "summary": "...",
  "sentiment": "Positive",
  "pdf_report": "/media/reports/report_5.pdf"
}
```

---

## Video Analysis Pipeline

When you send a video to Sense AI, it runs a full multimodal analysis pipeline:

```
Video File
    â”‚
    â”œâ”€â”€â–º Frame Extraction (every 5th frame, MD5 deduplicated)
    â”‚         â””â”€â”€â–º Keras CNN â†’ emotion per frame â†’ timeline + statistics
    â”‚
    â”œâ”€â”€â–º Audio Extraction (ffmpeg â†’ PCM WAV 44.1kHz)
    â”‚         â””â”€â”€â–º Whisper ASR â†’ transcription
    â”‚                   â””â”€â”€â–º Extractive summarizer (30% ratio)
    â”‚                   â””â”€â”€â–º TF-IDF + sklearn â†’ sentiment
    â”‚
    â””â”€â”€â–º PDF Report (ReportLab)
              â”œâ”€â”€ Emotion distribution table
              â”œâ”€â”€ Emotion-over-time chart (matplotlib)
              â”œâ”€â”€ Transcription + summary
              â””â”€â”€ Sentiment result
```

---

## Tech Stack

| Category | Technology |
|---|---|
| Web Framework | Django 5.2 + Django REST Framework 3.16 |
| Deep Learning | TensorFlow 2.19 Â· Keras 3.9 Â· PyTorch 2.6 |
| Face Detection | DeepFace Â· MTCNN Â· RetinaFace Â· MediaPipe |
| Speech Recognition | OpenAI Whisper (base) |
| NLP | HuggingFace Transformers 4.36 Â· NLTK 3.9 Â· scikit-learn 1.6 |
| Audio Processing | Librosa 0.11 Â· SoundFile Â· audioread |
| Video Processing | OpenCV 4.11 Â· MoviePy Â· ffmpeg |
| PDF Generation | ReportLab 4.3 |
| Visualization | Matplotlib |
| Server | Gunicorn + ASGI |
| Process Manager | PM2 |

---

## Getting Started

### Prerequisites
- Python 3.11+
- ffmpeg (bundled in `/static/ffmpeg/`)
- 8GB+ RAM (for loading Whisper + BART simultaneously)
- GPU recommended for video inference

### Installation

```bash
git clone https://github.com/mgalal0/Sense_Ai.git
cd Sense_Ai

python -m venv venv
source venv/bin/activate       # Linux/macOS
venv\Scripts\activate          # Windows

pip install -r requirements.txt

python manage.py migrate
python manage.py runserver
```

> Models are loaded automatically at server startup from `/static/`. No manual download needed.

---

## Team

<table>
  <tr>
    <td align="center">
      <b>Mahmoud Galal</b><br/>
      <sub>Backend & API Engineering</sub>
    </td>
    <td align="center">
      <b>Adham Ismail</b><br/>
      <sub>AI & Machine Learning Engineering</sub>
    </td>
  </tr>
</table>

---

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=100&section=footer" width="100%"/>

</div>
